{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7TWxFey66GR9PnkHY9sGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thee-smarty/Camouflage-Military-Soldier-Density-Estimation/blob/main/camouflage_military_soldier_density_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwqlQDPOL1jy"
      },
      "outputs": [],
      "source": [
        "# Install Ultralytics library\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable warnings in the notebook to maintain clean output cells\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import yaml\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Video"
      ],
      "metadata": {
        "id": "NS57WbvLMELJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the visual appearance of Seaborn plots\n",
        "sns.set(rc={'axes.facecolor': '#eae8fa'}, style='darkgrid')"
      ],
      "metadata": {
        "id": "yRT8Y6vUMEmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our real-time camouflage military soldier density estimation application : YOLOv8 nano pre-trained model (yolov8n.pt)"
      ],
      "metadata": {
        "id": "ZOQZ7l7tM3pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained YOLOv8n model from Ultralytics\n",
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "rwGL6CBeMEvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the image file\n",
        "image_path = './image.jpg'\n",
        "\n",
        "# Perform inference on the provided image(s)\n",
        "results = model.predict(source=image_path,\n",
        "                        imgsz=640,  # Resize image to 640x640 (the size pf images the model was trained on)\n",
        "                        conf=0.5)   # Confidence threshold: 50% (only detections above 50% confidence will be considered)\n",
        "\n",
        "# Annotate and convert image to numpy array\n",
        "sample_image = results[0].plot(line_width=2)\n",
        "\n",
        "# Convert the color of the image from BGR to RGB for correct color representation in matplotlib\n",
        "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display annotated image\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.imshow(sample_image)\n",
        "plt.title('Detected Objects in Sample Image by the Pre-trained YOLOv8 Model on COCO Dataset', fontsize=20)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bnfEmo1OME3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset_path\n",
        "dataset_path = './Dataset'\n",
        "\n",
        "# Set the path to the YAML file\n",
        "yaml_file_path = os.path.join(dataset_path, 'data.yaml')\n",
        "\n",
        "# Load and print the contents of the YAML file\n",
        "with open(yaml_file_path, 'r') as file:\n",
        "    yaml_content = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    print(yaml.dump(yaml_content, default_flow_style=False))"
      ],
      "metadata": {
        "id": "Zmip9h4RME9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths for training and validation image sets\n",
        "train_images_path = os.path.join(dataset_path, 'train', 'images')\n",
        "valid_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
        "\n",
        "# Initialize counters for the number of images\n",
        "num_train_images = 0\n",
        "num_valid_images = 0\n",
        "\n",
        "# Initialize sets to hold the unique sizes of images\n",
        "train_image_sizes = set()\n",
        "valid_image_sizes = set()\n",
        "\n",
        "# Check train images sizes and count\n",
        "for filename in os.listdir(train_images_path):\n",
        "    if filename.endswith('.jpg'):\n",
        "        num_train_images += 1\n",
        "        image_path = os.path.join(train_images_path, filename)\n",
        "        with Image.open(image_path) as img:\n",
        "            train_image_sizes.add(img.size)\n",
        "\n",
        "# Check validation images sizes and count\n",
        "for filename in os.listdir(valid_images_path):\n",
        "    if filename.endswith('.jpg'):\n",
        "        num_valid_images += 1\n",
        "        image_path = os.path.join(valid_images_path, filename)\n",
        "        with Image.open(image_path) as img:\n",
        "            valid_image_sizes.add(img.size)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of validation images: {num_valid_images}\")\n",
        "\n",
        "# Check if all images in training set have the same size\n",
        "if len(train_image_sizes) == 1:\n",
        "    print(f\"All training images have the same size: {train_image_sizes.pop()}\")\n",
        "else:\n",
        "    print(\"Training images have varying sizes.\")\n",
        "\n",
        "# Check if all images in validation set have the same size\n",
        "if len(valid_image_sizes) == 1:\n",
        "    print(f\"All validation images have the same size: {valid_image_sizes.pop()}\")\n",
        "else:\n",
        "    print(\"Validation images have varying sizes.\")"
      ],
      "metadata": {
        "id": "zrt1MOtpMFB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all jpg images in the directory\n",
        "image_files = [file for file in os.listdir(train_images_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Select 8 images at equal intervals\n",
        "num_images = len(image_files)\n",
        "selected_images = [image_files[i] for i in range(0, num_images, num_images // 8)]\n",
        "\n",
        "# Create a 2x4 subplot\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 11))\n",
        "\n",
        "# Display each of the selected images\n",
        "for ax, img_file in zip(axes.ravel(), selected_images):\n",
        "    img_path = os.path.join(train_images_path, img_file)\n",
        "    image = Image.open(img_path)\n",
        "    ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Sample Images from Training Dataset', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7L18uviwMFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on our custom dataset\n",
        "results = model.train(\n",
        "    data=yaml_file_path,     # Path to the dataset configuration file\n",
        "    epochs=100,              # Number of epochs to train for\n",
        "    imgsz=640,               # Size of input images as integer\n",
        "    device=0,                # Device to run on, i.e. cuda device=0\n",
        "    patience=50,             # Epochs to wait for no observable improvement for early stopping of training\n",
        "    batch=32,                # Number of images per batch\n",
        "    optimizer='auto',        # Optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n",
        "    lr0=0.0001,              # Initial learning rate\n",
        "    lrf=0.1,                 # Final learning rate (lr0 * lrf)\n",
        "    dropout=0.1,             # Use dropout regularization\n",
        "    seed=0                   # Random seed for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "N_odN1UDMFK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Post-Training*"
      ],
      "metadata": {
        "id": "nlxmygZcOGYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory\n",
        "post_training_files_path = './runs/detect/train'\n",
        "\n",
        "# List the files in the directory\n",
        "!ls {post_training_files_path}"
      ],
      "metadata": {
        "id": "R4GWTVG5MFPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot learning curves for loss values\n",
        "def plot_learning_curve(df, train_loss_col, val_loss_col, title):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.lineplot(data=df, x='epoch', y=train_loss_col, label='Train Loss', color='#141140', linestyle='-', linewidth=2)\n",
        "    sns.lineplot(data=df, x='epoch', y=val_loss_col, label='Validation Loss', color='orangered', linestyle='--', linewidth=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QvFKPr7FMFTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the full file path for 'results.csv' using the directory path and file name\n",
        "results_csv_path = os.path.join(post_training_files_path, 'results.csv')\n",
        "\n",
        "# Load the CSV file from the constructed path into a pandas DataFrame\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# Remove any leading whitespace from the column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Plot the learning curves for each loss\n",
        "plot_learning_curve(df, 'train/box_loss', 'val/box_loss', 'Box Loss Learning Curve')\n",
        "plot_learning_curve(df, 'train/cls_loss', 'val/cls_loss', 'Classification Loss Learning Curve')\n",
        "plot_learning_curve(df, 'train/dfl_loss', 'val/dfl_loss', 'Distribution Focal Loss Learning Curve')"
      ],
      "metadata": {
        "id": "_PFIKXONMFX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the path to the normalized confusion matrix image\n",
        "confusion_matrix_path = os.path.join(post_training_files_path, 'confusion_matrix_normalized.png')\n",
        "\n",
        "# Read the image using cv2\n",
        "cm_img = cv2.imread(confusion_matrix_path)\n",
        "\n",
        "# Convert the image from BGR to RGB color space for accurate color representation with matplotlib\n",
        "cm_img = cv2.cvtColor(cm_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(10, 10), dpi=120)\n",
        "plt.imshow(cm_img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HjHHXV2bMFcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the path to the best model weights file using os.path.join\n",
        "best_model_path = os.path.join(post_training_files_path, 'weights/best.pt')\n",
        "\n",
        "# Load the best model weights into the YOLO model\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Validate the best model using the validation set with default parameters\n",
        "metrics = best_model.val(split='val')"
      ],
      "metadata": {
        "id": "XLcCYLltMFga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dictionary to a pandas DataFrame and use the keys as the index\n",
        "metrics_df = pd.DataFrame.from_dict(metrics.results_dict, orient='index', columns=['Metric Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "metrics_df.round(3)"
      ],
      "metadata": {
        "id": "cbDdI5PxMFlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the validation images\n",
        "valid_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
        "\n",
        "# List all jpg images in the directory\n",
        "image_files = [file for file in os.listdir(valid_images_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Select 9 images at equal intervals\n",
        "num_images = len(image_files)\n",
        "selected_images = [image_files[i] for i in range(0, num_images, num_images // 9)]\n",
        "\n",
        "# Initialize the subplot\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 21))\n",
        "fig.suptitle('Validation Set Inferences', fontsize=24)\n",
        "\n",
        "# Perform inference on each selected image and display it\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    image_path = os.path.join(valid_images_path, selected_images[i])\n",
        "    results = best_model.predict(source=image_path, imgsz=640, conf=0.5)\n",
        "    annotated_image = results[0].plot(line_width=1)\n",
        "    annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "    ax.imshow(annotated_image_rgb)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "afIpa9xlOwer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the image file\n",
        "sample_image_path = './image.jpg'\n",
        "\n",
        "# Perform inference on the provided image using best model\n",
        "results = best_model.predict(source=sample_image_path, imgsz=640, conf=0.7)\n",
        "\n",
        "# Annotate and convert image to numpy array\n",
        "sample_image = results[0].plot(line_width=2)\n",
        "\n",
        "# Convert the color of the image from BGR to RGB for correct color representation in matplotlib\n",
        "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display annotated image\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.imshow(sample_image)\n",
        "plt.title('Detected Objects in Sample Image by the Fine-tuned YOLOv8 Model', fontsize=20)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "am9c0rWoOwpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
